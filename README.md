# Dissertation code
In my MSc thesis in Mathematics I studied the training process of the Restricted Boltzmann Machines.  
Here I've loaded part of the code that I wrote to test the theoretical results.

## Dissertation abstract
In this thesis, we dealt with Restricted Boltzmann Machines with binary priors as models of unsupervised learning, analyzing the role of the number of hidden neurons on the amount of examples needed for successful training. We simulated a teacher-student scenario and calculated the efficiency of the machine under the assumption of replica symmetry to study the location of the critical threshold beyond which learning begins.
Our results confirm the conjecture that, in the absence of correlation between the weights of the data-generating machine, the critical threshold does not depend on the number of hidden units (as long as it is finite) and thus on the complexity of the data. Instead, the presence of correlation significantly reduces the amount of examples needed for training. We have shown that this effect becomes more pronounced as the number of hidden units increases.
The entire analysis is supported by numerical simulations that corroborate the results.

## Continuation and contributions
Hopefully I'll continue the research and update the code from time to time.  
Any contribution or question is welcome, open an issue or contact me on LinkedIn: https://www.linkedin.com/in/francescotosello/

## Language
I apologize for the comments and descriptions being in italian.
When I realized that it may have been useful to write the project (and the thesis) in english, it was already too late.
In any case it shouldn't be too difficult to understand the code.
